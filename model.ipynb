{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laura Flaherty - G00348586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Create, document, and train a model that recognises hand-written digits using the MNIST dataset </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "import tensorflow and MNIST dataset under the Keras API.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "## the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print('import tensorflow and MNIST dataset under the Keras API.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>input image dimensions </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Plot a single image from the index of images and label it correctly</h3>\n",
    "<p>Note that matplotlib may not always work </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x184ea9d2848>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index = 40347 \n",
    "print(y_train[image_index]) # The label is 5\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Looks at the shape of the dataset</h3>\n",
    "<p>This shows that there are 60,000 samples in the training set. The images are 28 x 28 px</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepocessing </h3>\n",
    "    <ul>\n",
    "        <li>Transform the dataset from having shape (n, width, height) to (n, depth, width, height)</li>\n",
    "        <li>Convert the data type to float32</li>\n",
    "        <li> normalize the RGB codes by dividing it it the max RGB value</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>The Model </H2>\n",
    "<h3>The Imports </h3>\n",
    "<ul>\n",
    "    <li> <b>Sequential</b> - a linear stack of neural network layers </li>\n",
    "    <li> <b>Layers</b> - core layers that are used in almost any neural network</li> <p>(Conv2D, Maxpooling 2D are convolutional layers that will help us efficiently train on image data)</p>\n",
    "</ul>\n",
    "<h3>Creating the Sequential Model and adding layers</h3>\n",
    "<ul>\n",
    "    <li><b>Conv2D </b> - spatial convolution over images</li>\n",
    "    <p>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs</p>\n",
    "    <br>\n",
    "    <li><b>MaxPooling2D</b> - Max pooling operation for spatial data.</li>\n",
    "    <p>The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned. Link to reference <a href=\"https://www.quora.com/What-is-max-pooling-in-convolutional-neural-networks\">here</a></p>\n",
    "    <br>\n",
    "    <li><b>Flatten</b> - reshapes the tensor to have the shape that is equal to the number of elements contained in tensor non including the batch dimension. </li>\n",
    "    <br>\n",
    "    <li><b>Dense</b> - represents a matrix vector multiplication. Just your regular densely-connected Neural Network layer.</li>\n",
    "    <p>128 is the number of samples that going to be propagated through the network at each epoch</p>\n",
    "     <br>\n",
    "    <li><b>Dropout</b> layers provide a simple way to avoid overfitting by randomly dropping components of neural network (outputs) from a layer of neural network.\n",
    "     <p>This results in a scenario where at each layer more neurons are forced to learn the multiple characteristics of the neural network. The last layer of the neural network will have number of node equal to the number of output class i.e. 10 and the activation function we will be using is softmax</p>\n",
    "</ul>\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The model.fit function</h3>\n",
    "<p>trains the model for a fixed number of epochs (iterations on a dataset).</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "60000/60000 [==============================] - 55s 917us/step - loss: 0.2025 - accuracy: 0.9391\n",
      "Epoch 2/13\n",
      "60000/60000 [==============================] - 57s 948us/step - loss: 0.0797 - accuracy: 0.9750\n",
      "Epoch 3/13\n",
      "60000/60000 [==============================] - 57s 957us/step - loss: 0.0546 - accuracy: 0.9826s - loss: 0.0\n",
      "Epoch 4/13\n",
      "60000/60000 [==============================] - 59s 976us/step - loss: 0.0447 - accuracy: 0.9856\n",
      "Epoch 5/13\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.0341 - accuracy: 0.9885\n",
      "Epoch 6/13\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.0282 - accuracy: 0.9907\n",
      "Epoch 7/13\n",
      "60000/60000 [==============================] - 52s 874us/step - loss: 0.0258 - accuracy: 0.9915\n",
      "Epoch 8/13\n",
      "60000/60000 [==============================] - 58s 968us/step - loss: 0.0213 - accuracy: 0.9929\n",
      "Epoch 9/13\n",
      "60000/60000 [==============================] - 57s 955us/step - loss: 0.0203 - accuracy: 0.9936\n",
      "Epoch 10/13\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.99 - 58s 966us/step - loss: 0.0172 - accuracy: 0.9940\n",
      "Epoch 11/13\n",
      "60000/60000 [==============================] - 57s 943us/step - loss: 0.0180 - accuracy: 0.9940\n",
      "Epoch 12/13\n",
      "60000/60000 [==============================] - 56s 941us/step - loss: 0.0163 - accuracy: 0.9946\n",
      "Epoch 13/13\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0142 - accuracy: 0.9951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x184e886c9c8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_train, epochs=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3>Loss and Accuracy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.76797 %\n",
      "Test accuracy: 98.57 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss: %g %%\"%(score[0]*100))\n",
    "print(\"Test accuracy: %g %%\"%(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3>Individual prediction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 421\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, img_rows, img_cols, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Save the model for later use</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
