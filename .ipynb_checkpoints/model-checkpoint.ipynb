{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import tensorflow and MNIST dataset under the Keras API.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print('import tensorflow and MNIST dataset under the Keras API.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "# num_classes = 10\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23528eb2e08>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index = 40347 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 150s 2ms/step - loss: 0.2075 - accuracy: 0.9372\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 150s 3ms/step - loss: 0.0839 - accuracy: 0.9741\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 151s 3ms/step - loss: 0.0602 - accuracy: 0.9815\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0456 - accuracy: 0.9852\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0382 - accuracy: 0.9874\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0290 - accuracy: 0.9901\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0255 - accuracy: 0.9915\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 154s 3ms/step - loss: 0.0236 - accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 150s 3ms/step - loss: 0.0194 - accuracy: 0.9939\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 151s 3ms/step - loss: 0.0205 - accuracy: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23527d55408>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.061681676959112225\n",
      "Test accuracy: 98.61999750137329\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss: %g %%\"%(score[0]*100))\n",
    "print(\"Test accuracy: %g %%\"%(score[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 500\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, img_rows, img_cols, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myenv] *",
   "language": "python",
   "name": "conda-env-.conda-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
